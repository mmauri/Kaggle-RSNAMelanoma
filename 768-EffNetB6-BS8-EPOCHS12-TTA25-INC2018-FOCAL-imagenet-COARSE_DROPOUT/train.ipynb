{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"inference_tf23.ipynb","provenance":[{"file_id":"15f91Bm3b6fXko_-_qU7K7DwBkXW2Ypz5","timestamp":1596957339308}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"lqaOVKBhbrWC","colab_type":"text"},"source":["# Triple Stratified KFold CV with TFRecords\n","This is a simple starter notebook for Kaggle's Melanoma Comp showing triple stratifed KFold with TFRecords. Triple stratified KFold is explained [here][2]. There are many configuration variables below to allow you to experiment. Use either GPU or TPU. You can control which size images are loaded, which efficientNets are used, and whether external data is used. You can experiment with different data augmentation, model architecture, loss, optimizers, and learning schedules. The TFRecords contain meta data, so you can input that into your CNN too. \n","\n","**NOTE:** this notebook lets you run a different experiment in each fold if you want to run lots of experiments. (Then it is like running multiple holdout validaiton experiments but in that case note that the overall CV score is meaningless because LB will be much higher when the multiple experiments are ensembled to predict test). **If you want a proper CV with a reliable overall CV score you need to choose the same configuration for each fold.**\n","\n","This notebook follows the 5 step process presented in my \"How to compete with GPUs Workshop\" [here][1]. Some code sections have been reused from AgentAuers' great notebook [here][3]\n","\n","[1]: https://www.kaggle.com/cdeotte/how-to-compete-with-gpus-workshop\n","[2]: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/165526\n","[3]: https://www.kaggle.com/agentauers/incredible-tpus-finetune-effnetb0-b6-at-once"]},{"cell_type":"code","metadata":{"id":"oK-3AAtBdDZ0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":120},"executionInfo":{"status":"ok","timestamp":1596957584810,"user_tz":-120,"elapsed":48162,"user":{"displayName":"Marc Mauri","photoUrl":"","userId":"05962595886095771500"}},"outputId":"d4e160e6-9b05-40ca-9696-1f16b9764a1c"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xCzN1_ekeKos","colab_type":"code","colab":{}},"source":["!pip install -q kaggle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"93oVZqGUdhx0","colab_type":"code","colab":{}},"source":["!mkdir -p ~/.kaggle\n","!cp \"/content/gdrive/My Drive/Kaggle/kaggle.json\" ~/.kaggle"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4SWh_akWzVtq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596957714108,"user_tz":-120,"elapsed":109362,"user":{"displayName":"Marc Mauri","photoUrl":"","userId":"05962595886095771500"}},"outputId":"42180781-2c23-4a03-8747-dfeb4c89d236"},"source":["# install tf 2.2 following kaggle post instructions\n","\n","!pip install tensorflow~=2.2.0 tensorflow_gcs_config~=2.2.0\n","import tensorflow as tf\n","import requests\n","import os\n","resp = requests.post(\"http://{}:8475/requestversion/{}\".format(os.environ[\"COLAB_TPU_ADDR\"].split(\":\")[0], tf.__version__))\n","if resp.status_code != 200:\n","  print(\"Failed to switch the TPU to TF {}\".format(version))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting tensorflow~=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/be/679ce5254a8c8d07470efb4a4c00345fae91f766e64f1c2aece8796d7218/tensorflow-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl (516.2MB)\n","\u001b[K     |████████████████████████████████| 516.2MB 27kB/s \n","\u001b[?25hCollecting tensorflow_gcs_config~=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/0b/c6fe9b75ba3999c10b7ab77e7d4019c90344bb79609a9378355ca6712598/tensorflow_gcs_config-2.2.0-py3-none-any.whl (392kB)\n","\u001b[K     |████████████████████████████████| 399kB 39.9MB/s \n","\u001b[?25hCollecting tensorflow-estimator<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/f5/926ae53d6a226ec0fda5208e0e581cffed895ccc89e36ba76a8e60895b78/tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454kB)\n","\u001b[K     |████████████████████████████████| 460kB 60.9MB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0) (0.34.2)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0) (1.1.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0) (1.15.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0) (3.12.4)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0) (1.1.0)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0) (0.2.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0) (0.9.0)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0) (2.10.0)\n","Collecting tensorboard<2.3.0,>=2.2.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/74/0a6fcb206dcc72a6da9a62dd81784bfdbff5fedb099982861dc2219014fb/tensorboard-2.2.2-py3-none-any.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 58.4MB/s \n","\u001b[?25hRequirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0) (0.3.3)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0) (1.18.5)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0) (1.4.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0) (1.30.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0) (1.12.1)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0) (1.6.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow~=2.2.0) (3.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow~=2.2.0) (49.2.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (3.2.2)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (1.7.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (0.4.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (1.17.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (1.0.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (1.7.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (1.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (4.6)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (4.1.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (2020.6.20)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (3.0.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (3.1.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow~=2.2.0) (0.4.8)\n","Installing collected packages: tensorflow-estimator, tensorboard, tensorflow, tensorflow-gcs-config\n","  Found existing installation: tensorflow-estimator 2.3.0\n","    Uninstalling tensorflow-estimator-2.3.0:\n","      Successfully uninstalled tensorflow-estimator-2.3.0\n","  Found existing installation: tensorboard 2.3.0\n","    Uninstalling tensorboard-2.3.0:\n","      Successfully uninstalled tensorboard-2.3.0\n","  Found existing installation: tensorflow 2.3.0\n","    Uninstalling tensorflow-2.3.0:\n","      Successfully uninstalled tensorflow-2.3.0\n","  Found existing installation: tensorflow-gcs-config 2.3.0\n","    Uninstalling tensorflow-gcs-config-2.3.0:\n","      Successfully uninstalled tensorflow-gcs-config-2.3.0\n","Successfully installed tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0 tensorflow-gcs-config-2.2.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NasrB1cVbrWJ","colab_type":"text"},"source":["# Initialize Environment"]},{"cell_type":"code","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"zB__-0KjbrWJ","colab_type":"code","colab":{}},"source":["!pip install -q efficientnet >> /dev/null"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jetxtbJFbrWQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1596957718364,"user_tz":-120,"elapsed":113609,"user":{"displayName":"Marc Mauri","photoUrl":"","userId":"05962595886095771500"}},"outputId":"a5cca5a9-207a-494b-a625-06ee16b53af4"},"source":["import cv2, matplotlib.pyplot as plt\n","import gc\n","import pandas as pd, numpy as np\n","#from kaggle_datasets import KaggleDatasets\n","import tensorflow as tf, re, math\n","import tensorflow.keras.backend as K\n","import efficientnet.tfkeras as efn\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import roc_auc_score\n","import matplotlib.pyplot as plt\n","print(tf.__version__)\n","print(tf.keras.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2.2.0\n","2.3.0-tf\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-vD_mQIBbrWW","colab_type":"text"},"source":["## Configuration\n","In order to be a proper cross validation with a meaningful overall CV score (aligned with LB score), **you need to choose the same** `IMG_SIZES`, `INC2019`, `INC2018`, and `EFF_NETS` **for each fold**. If your goal is to just run lots of experiments, then you can choose to have a different experiment in each fold. Then each fold is like a holdout validation experiment. When you find a configuration you like, you can use that configuration for all folds. \n","* DEVICE - is GPU or TPU\n","* SEED - a different seed produces a different triple stratified kfold split.\n","* FOLDS - number of folds. Best set to 3, 5, or 15 but can be any number between 2 and 15\n","* IMG_SIZES - is a Python list of length FOLDS. These are the image sizes to use each fold\n","* INC2019 - This includes the new half of the 2019 competition data. The second half of the 2019 data is the comp data from 2018 plus 2017\n","* INC2018 - This includes the second half of the 2019 competition data which is the comp data from 2018 plus 2017\n","* BATCH_SIZES - is a list of length FOLDS. These are batch sizes for each fold. For maximum speed, it is best to use the largest batch size your GPU or TPU allows.\n","* EPOCHS - is a list of length FOLDS. These are maximum epochs. Note that each fold, the best epoch model is saved and used. So if epochs is too large, it won't matter.\n","* EFF_NETS - is a list of length FOLDS. These are the EfficientNets to use each fold. The number refers to the B. So a number of `0` refers to EfficientNetB0, and `1` refers to EfficientNetB1, etc.\n","* WGTS - this should be `1/FOLDS` for each fold. This is the weight when ensembling the folds to predict the test set. If you want a weird ensemble, you can use different weights.\n","* TTA - test time augmentation. Each test image is randomly augmented and predicted TTA times and the average prediction is used. TTA is also applied to OOF during validation."]},{"cell_type":"code","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","id":"LwY5husgbrWX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1596957718365,"user_tz":-120,"elapsed":113605,"user":{"displayName":"Marc Mauri","photoUrl":"","userId":"05962595886095771500"}},"outputId":"b136c0f3-87fc-4ac2-8926-ab60a13fc318"},"source":["DEVICE = \"TPU\" #or \"GPU\"\n","\n","# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD\n","SEED = 42\n","\n","# NUMBER OF FOLDS. USE 3, 5, OR 15 \n","FOLDS = 5\n","\n","# WHICH IMAGE SIZES TO LOAD EACH FOLD\n","# CHOOSE 128, 192, 256, 384, 512, 768 \n","IMG_SIZES =  [512,512,512,512,512]\n","IMG_SIZES = [384,384,384,384,384]\n","IMG_SIZES = [768]*FOLDS\n","\n","\n","# INCLUDE OLD COMP DATA? YES=1 NO=0\n","INC2019 = [0,0,0,0,0]\n","INC2018 = [1,1,1,1,1]\n","\n","# BATCH SIZE AND EPOCHS\n","BATCH_SIZES = [8]*FOLDS #[32]*FOLDS\n","EPOCHS = [12]*FOLDS #12 18\n","\n","# WHICH EFFICIENTNET B? TO USE\n","EFF_NETS = [7,7,7,7,7]\n","EFF_NETS = [3,3,3,3,3]\n","EFF_NETS = [6,6,6,6,6]\n","\n","#MODEL_NAME = 'ResNet152' #EfficientNetB0\n","\n","\n","DROP_FREQ = [0.75] * FOLDS # between 0 and 1\n","DROP_CT = [8] * FOLDS # may slow training if CT>16\n","DROP_SIZE = [0.2] *FOLDS # between 0 and 1\n","\n","EFF_NET_PRETRAIN = 'imagenet' #''noisy-student\n","\n","# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST\n","WGTS = [1/FOLDS]*FOLDS\n","\n","# TEST TIME AUGMENTATION STEPS\n","TTA = 25\n","\n","#Treure de Kaggle\n","if IMG_SIZES[0]==384:\n","  #384 images\n","  GCS1=\"gs://kds-71b679af6661316328cfa122f5342b4a84fe0c7c1135d809fbee8ca4\" #384\n","  GCS2=\"gs://kds-9fc526a7f92f5454bc790655a916878883ad270d1e13c91e7d527659\"#384\n","elif IMG_SIZES[0]==512:\n","  #512\n","  GCS1 = 'gs://kds-df537acf009e02b1d4427274d18970a1b0101b1ca26824bae39b5b4b'\n","  GCS2 = 'gs://kds-25423645f76650f9220fbd3613366c3c5a524b3a7d7663b6e3137c57'\n","elif IMG_SIZES[0]==768:\n","  GCS1='gs://kds-cfb16ed5f55adb5ab35a75a2fe74c3dc11a4b869dc8cfb3d9b1759e1'\n","  GCS2='gs://kds-79d9c56dcae7978f98a6bbe8318ac6866ba4778fc95c5871fcfd0f03'\n","  \n","  \n","\n","else:\n","  raise error\n","\n","MODEL = f'{IMG_SIZES[0]}-EffNetB{EFF_NETS[0]}-BS{BATCH_SIZES[0]}-EPOCHS{EPOCHS[0]}-TTA{TTA}-INC2018-FOCAL-{EFF_NET_PRETRAIN}-COARSE_DROPOUT'\n","#MODEL = f'{IMG_SIZES[0]}-{MODEL_NAME}-BS{BATCH_SIZES[0]}-EPOCHS{EPOCHS[0]}-TTA{TTA}-INC2018-FOCAL-{EFF_NET_PRETRAIN}-COARSE_DROPOUT'\n","print(MODEL)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["768-EffNetB6-BS8-EPOCHS12-TTA25-INC2018-FOCAL-imagenet-COARSE_DROPOUT\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T4m1m0pbs1Ee","colab_type":"code","colab":{}},"source":["import os\n","if not os.path.exists(f'/content/{MODEL}'):\n","    os.mkdir(f'/content/{MODEL}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WpQs0ydZ2rfT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1596958248942,"user_tz":-120,"elapsed":5235,"user":{"displayName":"Marc Mauri","photoUrl":"","userId":"05962595886095771500"}},"outputId":"a07a50d0-e818-487d-cac4-1e015419fc0c"},"source":["import os\n","src = f'/content/'\n","dest = f'\"/content/gdrive/My Drive/saved_models/{MODEL}/\"'\n","os.system(f\"cp  -rf {dest} {src}\")\n","print (src)\n","print(dest)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["/content/\n","\"/content/gdrive/My Drive/saved_models/768-EffNetB6-BS8-EPOCHS12-TTA25-INC2018-FOCAL-imagenet-COARSE_DROPOUT/\"\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qVe8puxqbrWc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":753},"executionInfo":{"status":"ok","timestamp":1596957786052,"user_tz":-120,"elapsed":181274,"user":{"displayName":"Marc Mauri","photoUrl":"","userId":"05962595886095771500"}},"outputId":"b24b5892-acfd-48f8-9613-98abb946049d"},"source":["if DEVICE == \"TPU\":\n","    print(\"connecting to TPU...\")\n","    try:\n","        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","        print('Running on TPU ', tpu.master())\n","    except ValueError:\n","        print(\"Could not connect to TPU\")\n","        tpu = None\n","\n","    if tpu:\n","        try:\n","            print(\"initializing  TPU ...\")\n","            tf.config.experimental_connect_to_cluster(tpu)\n","            tf.tpu.experimental.initialize_tpu_system(tpu)\n","            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","            print(\"TPU initialized\")\n","        except _:\n","            print(\"failed to initialize TPU\")\n","    else:\n","        DEVICE = \"GPU\"\n","\n","if DEVICE != \"TPU\":\n","    print(\"Using default strategy for CPU and single GPU\")\n","    strategy = tf.distribute.get_strategy()\n","\n","if DEVICE == \"GPU\":\n","    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n","    \n","\n","AUTO     = tf.data.experimental.AUTOTUNE\n","REPLICAS = strategy.num_replicas_in_sync"],"execution_count":null,"outputs":[{"output_type":"stream","text":["connecting to TPU...\n","Running on TPU  grpc://10.51.118.138:8470\n","initializing  TPU ...\n","INFO:tensorflow:Initializing the TPU system: grpc://10.51.118.138:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.51.118.138:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["TPU initialized\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aNw8tG6ubrWg","colab_type":"text"},"source":["# Step 1: Preprocess\n","Preprocess has already been done and saved to TFRecords. Here we choose which size to load. We can use either 128x128, 192x192, 256x256, 384x384, 512x512, 768x768 by changing the `IMG_SIZES` variable in the preceeding code section. These TFRecords are discussed [here][1]. The advantage of using different input sizes is discussed [here][2]\n","\n","[1]: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/155579\n","[2]: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/160147"]},{"cell_type":"code","metadata":{"id":"qWvtjo6GbrWi","colab_type":"code","colab":{}},"source":["GCS_PATH = [None]*FOLDS; GCS_PATH2 = [None]*FOLDS\n","\n","for i,k in enumerate(IMG_SIZES):\n","    GCS_PATH[i] = GCS1\n","    GCS_PATH2[i] = GCS2\n","\n","files_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))\n","files_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwYqgXxybrWm","colab_type":"text"},"source":["# Step 2: Data Augmentation\n","This notebook uses rotation, sheer, zoom, shift augmentation first shown in this notebook [here][1] and successfully used in Melanoma comp by AgentAuers [here][2]. This notebook also uses horizontal flip, hue, saturation, contrast, brightness augmentation similar to last years winner and also similar to AgentAuers' notebook.\n","\n","Additionally we can decide to use external data by changing the variables `INC2019` and `INC2018` in the preceeding code section. These variables respectively indicate whether to load last year 2019 data and/or year 2018 + 2017 data. These datasets are discussed [here][3]\n","\n","Consider experimenting with different augmenation and/or external data. The code to load TFRecords is taken from AgentAuers' notebook [here][2]. Thank you AgentAuers, this is great work.\n","\n","[1]: https://www.kaggle.com/cdeotte/rotation-augmentation-gpu-tpu-0-96\n","[2]: https://www.kaggle.com/agentauers/incredible-tpus-finetune-effnetb0-b6-at-once\n","[3]: https://www.kaggle.com/c/siim-isic-melanoma-classification/discussion/164910"]},{"cell_type":"code","metadata":{"id":"3FgAc9kibrWn","colab_type":"code","colab":{}},"source":["ROT_ = 180.0 #90.0 al submit anterior\n","SHR_ = 2.0\n","HZOOM_ = 8.0\n","WZOOM_ = 8.0\n","HSHIFT_ = 8.0\n","WSHIFT_ = 8.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QqW5bymlf5xS","colab_type":"code","colab":{}},"source":["def dropout(image, DIM=256, PROBABILITY = 0.75, CT = 8, SZ = 0.2):\n","    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n","    # output - image with CT squares of side size SZ*DIM removed\n","    \n","    # DO DROPOUT WITH PROBABILITY DEFINED ABOVE\n","    P = tf.cast( tf.random.uniform([],0,1)<PROBABILITY, tf.int32)\n","    if (P==0)|(CT==0)|(SZ==0): return image\n","    \n","    for k in range(CT):\n","        # CHOOSE RANDOM LOCATION\n","        x = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n","        y = tf.cast( tf.random.uniform([],0,DIM),tf.int32)\n","        # COMPUTE SQUARE \n","        WIDTH = tf.cast( SZ*DIM,tf.int32) * P\n","        ya = tf.math.maximum(0,y-WIDTH//2)\n","        yb = tf.math.minimum(DIM,y+WIDTH//2)\n","        xa = tf.math.maximum(0,x-WIDTH//2)\n","        xb = tf.math.minimum(DIM,x+WIDTH//2)\n","        # DROPOUT IMAGE\n","        one = image[ya:yb,0:xa,:]\n","        # two = tf.zeros([yb-ya,xb-xa,3],tf.bfloat16) \n","        two = tf.zeros([yb-ya,xb-xa,3])\n","        three = image[ya:yb,xb:DIM,:]\n","        middle = tf.concat([one,two,three],axis=1)\n","        image = tf.concat([image[0:ya,:,:],middle,image[yb:DIM,:,:]],axis=0)\n","            \n","    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR \n","    image = tf.reshape(image,[DIM,DIM,3])\n","    return image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D_GiWuG9brWr","colab_type":"code","colab":{}},"source":["def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n","    # returns 3x3 transformmatrix which transforms indicies\n","        \n","    # CONVERT DEGREES TO RADIANS\n","    rotation = math.pi * rotation / 180.\n","    shear    = math.pi * shear    / 180.\n","\n","    def get_3x3_mat(lst):\n","        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n","    \n","    # ROTATION MATRIX\n","    c1   = tf.math.cos(rotation)\n","    s1   = tf.math.sin(rotation)\n","    one  = tf.constant([1],dtype='float32')\n","    zero = tf.constant([0],dtype='float32')\n","    \n","    rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n","                                   -s1,  c1,   zero, \n","                                   zero, zero, one])    \n","    # SHEAR MATRIX\n","    c2 = tf.math.cos(shear)\n","    s2 = tf.math.sin(shear)    \n","    \n","    shear_matrix = get_3x3_mat([one,  s2,   zero, \n","                                zero, c2,   zero, \n","                                zero, zero, one])        \n","    # ZOOM MATRIX\n","    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero, \n","                               zero,            one/width_zoom, zero, \n","                               zero,            zero,           one])    \n","    # SHIFT MATRIX\n","    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n","                                zero, one,  width_shift, \n","                                zero, zero, one])\n","    \n","    return K.dot(K.dot(rotation_matrix, shear_matrix), \n","                 K.dot(zoom_matrix,     shift_matrix))\n","\n","\n","def transform(image, DIM=256):    \n","    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n","    # output - image randomly rotated, sheared, zoomed, and shifted\n","    XDIM = DIM%2 #fix for size 331\n","    \n","    rot = ROT_ * tf.random.normal([1], dtype='float32')\n","    shr = SHR_ * tf.random.normal([1], dtype='float32') \n","    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / HZOOM_\n","    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / WZOOM_\n","    h_shift = HSHIFT_ * tf.random.normal([1], dtype='float32') \n","    w_shift = WSHIFT_ * tf.random.normal([1], dtype='float32') \n","\n","    # GET TRANSFORMATION MATRIX\n","    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n","\n","    # LIST DESTINATION PIXEL INDICES\n","    x   = tf.repeat(tf.range(DIM//2, -DIM//2,-1), DIM)\n","    y   = tf.tile(tf.range(-DIM//2, DIM//2), [DIM])\n","    z   = tf.ones([DIM*DIM], dtype='int32')\n","    idx = tf.stack( [x,y,z] )\n","    \n","    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n","    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n","    idx2 = K.cast(idx2, dtype='int32')\n","    idx2 = K.clip(idx2, -DIM//2+XDIM+1, DIM//2)\n","    \n","    # FIND ORIGIN PIXEL VALUES           \n","    idx3 = tf.stack([DIM//2-idx2[0,], DIM//2-1+idx2[1,]])\n","    d    = tf.gather_nd(image, tf.transpose(idx3))\n","        \n","    return tf.reshape(d,[DIM, DIM,3])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Wv4PiQGbrWu","colab_type":"code","colab":{}},"source":["def read_labeled_tfrecord(example):\n","    tfrec_format = {\n","        'image'                        : tf.io.FixedLenFeature([], tf.string),\n","        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n","        'patient_id'                   : tf.io.FixedLenFeature([], tf.int64),\n","        'sex'                          : tf.io.FixedLenFeature([], tf.int64),\n","        'age_approx'                   : tf.io.FixedLenFeature([], tf.int64),\n","        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64),\n","        'diagnosis'                    : tf.io.FixedLenFeature([], tf.int64),\n","        'target'                       : tf.io.FixedLenFeature([], tf.int64)\n","    }           \n","    example = tf.io.parse_single_example(example, tfrec_format)\n","    #return example['image'], example['target']\n","    return example['image'], tf.cast(example['target'],tf.float32)\n","    # return example['image'], tf.cast(example['target'],tf.bfloat16)\n","\n","\n","def read_unlabeled_tfrecord(example, return_image_name):\n","    tfrec_format = {\n","        'image'                        : tf.io.FixedLenFeature([], tf.string),\n","        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n","    }\n","    example = tf.io.parse_single_example(example, tfrec_format)\n","    return example['image'], example['image_name'] if return_image_name else 0\n","\n"," \n","def prepare_image(img, augment=True, dim=256, droprate=0, dropct=0, dropsize=0):    \n","    img = tf.image.decode_jpeg(img, channels=3)\n","    # img = tf.cast(img, tf.bfloat16) / 255.0\n","    img = tf.cast(img, tf.float32) / 255.0\n","    \n","    if augment:\n","        img = transform(img,DIM=dim)\n","        if (droprate!=0)&(dropct!=0)&(dropsize!=0): \n","            img = dropout(img, DIM=dim, PROBABILITY=droprate, CT=dropct, SZ=dropsize)\n","        img = tf.image.random_flip_left_right(img)\n","        #img = tf.image.random_hue(img, 0.01)\n","        img = tf.image.random_saturation(img, 0.7, 1.3)\n","        img = tf.image.random_contrast(img, 0.8, 1.2)\n","        img = tf.image.random_brightness(img, 0.1)\n","\n","    # img = tf.cast(img, tf.bfloat16)              \n","    img = tf.reshape(img, [dim,dim, 3])\n","        \n","    return img\n","\n","def count_data_items(filenames):\n","    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) \n","         for filename in filenames]\n","    return np.sum(n)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GKhMlLtMbrWy","colab_type":"code","colab":{}},"source":["def get_dataset(files, augment = False, shuffle = False, repeat = False, \n","                labeled=True, return_image_names=True, batch_size=16, dim=256,\n","                droprate=0, dropct=0, dropsize=0):\n","    \n","    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n","    ds = ds.cache()\n","    \n","    if repeat:\n","        ds = ds.repeat()\n","    \n","    if shuffle: \n","        ds = ds.shuffle(1024*2) #if too large causes OOM in GPU CPU\n","        opt = tf.data.Options()\n","        opt.experimental_deterministic = False\n","        ds = ds.with_options(opt)\n","        \n","    if labeled: \n","        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n","    else:\n","        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_names), \n","                    num_parallel_calls=AUTO)      \n","    \n","    ds = ds.map(lambda img, imgname_or_label: (\n","                prepare_image(img, augment=augment, dim=dim, \n","                              droprate=droprate, dropct=dropct, dropsize=dropsize), \n","                imgname_or_label), \n","                num_parallel_calls=AUTO)\n","    \n","    ds = ds.batch(batch_size * REPLICAS)\n","    ds = ds.prefetch(AUTO)\n","    return ds"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vqwT89YRbrW5","colab_type":"text"},"source":["# Step 3: Build Model\n","This is a common model architecute. Consider experimenting with different backbones, custom heads, losses, and optimizers. Also consider inputing meta features into your CNN."]},{"cell_type":"code","metadata":{"id":"bgqRP-DnbrW6","colab_type":"code","colab":{}},"source":["import tensorflow_addons as tfa\n","\n","EFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n","        efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6, efn.EfficientNetB7, efn.EfficientNetL2]\n","\n","def build_model(dim=128, ef=0):\n","    inp = tf.keras.layers.Input(shape=(dim,dim,3))\n","    base = EFNS[ef](input_shape=(dim,dim,3),weights=EFF_NET_PRETRAIN,include_top=False)\n","    #base.trainable = True\n","    #print(base.trainable)\n","    x = base(inp)\n","    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n","    x = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n","    model = tf.keras.Model(inputs=inp,outputs=x)\n","    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n","    # loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05) \n","    loss = tfa.losses.SigmoidFocalCrossEntropy()\n","    model.compile(optimizer=opt,loss=loss,metrics=['AUC'])\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w-ozs_bvroqj","colab_type":"code","colab":{}},"source":["from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n","#from tensorflow.keras.applications.resnet_v2\n","from tensorflow.keras.applications import DenseNet121\n","import tensorflow.keras.applications.inception_resnet_v2 as InceptionResnetV2\n","from tensorflow.keras.models import Sequential , Model\n","from tensorflow.keras.layers import Dense, Conv2D, ReLU, Dropout, Flatten, Activation, GlobalAveragePooling2D, AveragePooling2D\n","from tensorflow.keras.layers import BatchNormalization"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ipPXxn30rqX4","colab_type":"code","colab":{}},"source":["import tensorflow_addons as tfa\n","\n","bool_focal_loss = True\n","bool_label_smoothing = False\n","\n","def get_model():\n","    name = MODEL_NAME\n","    img_size = IMG_SIZES[0]\n","\n","    if name == \"EfficientNetB0\":        \n","        base_model = tf.keras.applications.EfficientNetB0(weights='noisy-student',\n","                               include_top = False,\n","                               input_shape=(img_size,img_size,3)\n","                              )            \n","    elif name == 'ResNet50':\n","        base_model = ResNet50(weights='imagenet',\n","                              include_top=False,\n","                              input_shape=(img_size,img_size,3))\n","    elif name == 'ResNet152':\n","        base_model = ResNet152V2(weights='imagenet',\n","                              include_top=False,\n","                              input_shape=(img_size,img_size,3))\n","    elif name == 'DenseNet121':       \n","        base_model = DenseNet121(weights='imagenet',\n","                                 include_top=False,\n","                                 input_shape=(img_size,img_size,3))\n","    elif name == 'MobileNet':\n","        base_model = MobileNet(weights='imagenet', \n","                               include_top=False,\n","                               input_shape=(img_size,img_size,3))\n","    elif name == 'IncepResnet':       \n","        base_model = InceptionResNetV2(weights='imagenet',\n","                                       include_top=False,\n","                                       input_shape=(img_size,img_size,3))\n","    elif name==\"ResNet50V2\":\n","        base_model = ResNet50V2(weights='imagenet',\n","                                       include_top=False,\n","                                       input_shape=(img_size,img_size,3))\n","\n","          \n","    x = base_model.output\n","    x = GlobalAveragePooling2D()(x)\n","    # x = L.Dense(1024,activation='relu')(x)\n","    # x = L.Dropout(0.5)(x,training=True)\n","    predictions = Dense(1 ,activation='sigmoid')(x)\n","    \n","    if bool_focal_loss : \n","        my_loss= tfa.losses.SigmoidFocalCrossEntropy(reduction=tf.keras.losses.Reduction.AUTO)\n","    elif bool_label_smoothing :\n","        my_loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=0.1)\n","    else :\n","        my_loss = 'binary_crossentropy'\n","\n","    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n","    model = Model(inputs=base_model.input, outputs=predictions)\n","    #model.compile(optimizer=opt, loss=my_loss, metrics=['accuracy', tf.keras.metrics.AUC()])\n","    model.compile(optimizer=opt,loss=my_loss,metrics=['AUC'])  \n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AKBASGKabrW9","colab_type":"text"},"source":["# Step 4: Train Schedule\n","This is a common train schedule for transfer learning. The learning rate starts near zero, then increases to a maximum, then decays over time. Consider changing the schedule and/or learning rates. Note how the learning rate max is larger with larger batches sizes. This is a good practice to follow."]},{"cell_type":"code","metadata":{"id":"GKNuEtctWct9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":293},"executionInfo":{"status":"ok","timestamp":1596957786431,"user_tz":-120,"elapsed":181626,"user":{"displayName":"Marc Mauri","photoUrl":"","userId":"05962595886095771500"}},"outputId":"6d6e8841-ed1e-4307-f23b-2b0531717871"},"source":["lr_start   = 0.000005\n","lr_max     = 0.00000125 * REPLICAS * BATCH_SIZES[0]\n","lr_min     = 0.000001\n","lr_ramp_ep = 5\n","lr_sus_ep  = 0\n","lr_decay   = 0.8\n","\n","def lrfn(epoch):\n","    if epoch < lr_ramp_ep:\n","        lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n","        \n","    elif epoch < lr_ramp_ep + lr_sus_ep:\n","        lr = lr_max\n","        \n","    else:\n","        lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n","        \n","    return lr\n","\n","\n","rng = [i for i in range(EPOCHS[0])]\n","y = [lrfn(x) for x in rng]\n","plt.plot(rng, [lrfn(x) for x in rng])\n","print(y[0], y[-1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["5e-06 2.170937600000001e-05\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"FvoNpHo1brW9","colab_type":"code","colab":{}},"source":["def get_lr_callback(batch_size=8):\n","    lr_start   = 0.000005\n","    lr_max     = 0.00000125 * REPLICAS * batch_size\n","    lr_min     = 0.000001\n","    lr_ramp_ep = 5\n","    lr_sus_ep  = 0\n","    lr_decay   = 0.8\n","   \n","    def lrfn(epoch):\n","        if epoch < lr_ramp_ep:\n","            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n","            \n","        elif epoch < lr_ramp_ep + lr_sus_ep:\n","            lr = lr_max\n","            \n","        else:\n","            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n","            \n","        return lr\n","\n","    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n","    return lr_callback"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OG9_V4xBbrXA","colab_type":"text"},"source":["## Train Model\n","Our model will be trained for the number of FOLDS and EPOCHS you chose in the configuration above. Each fold the model with lowest validation loss will be saved and used to predict OOF and test. Adjust the variables `VERBOSE` and `DISPLOY_PLOT` below to determine what output you want displayed. The variable `VERBOSE=1 or 2` will display the training and validation loss and auc for each epoch as text. The variable `DISPLAY_PLOT` shows this information as a plot. "]},{"cell_type":"code","metadata":{"id":"tHlbZvhkbrXB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1596969159133,"user_tz":-120,"elapsed":1668723,"user":{"displayName":"Marc Mauri","photoUrl":"","userId":"05962595886095771500"}},"outputId":"7df65a31-25de-4d32-8817-534ee927a866"},"source":["# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit\n","VERBOSE = 1\n","DISPLAY_PLOT = True\n","\n","skf = KFold(n_splits=FOLDS,shuffle=True,random_state=SEED)\n","oof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = [] \n","preds = np.zeros((count_data_items(files_test),1))\n","preds_by_fold = np.empty([count_data_items(files_test), FOLDS], dtype=float)\n","\n","for fold,(idxT,idxV) in enumerate(skf.split(np.arange(15))):\n","  #if fold==4:\n","    # DISPLAY FOLD INFO\n","    if DEVICE=='TPU':\n","        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n","    print('#'*25); print('#### FOLD',fold+1)\n","    print('#### Image Size %i with {MODEL_NAME} EfficientNet B%i and batch_size %i'%\n","          (IMG_SIZES[fold],EFF_NETS[fold],BATCH_SIZES[fold]*REPLICAS))\n","    \n","    # CREATE TRAIN AND VALIDATION SUBSETS\n","    files_train = tf.io.gfile.glob([GCS_PATH[fold] + '/train%.2i*.tfrec'%x for x in idxT])\n","    if INC2019[fold]:\n","        files_train += tf.io.gfile.glob([GCS_PATH2[fold] + '/train%.2i*.tfrec'%x for x in idxT*2+1])\n","        print('#### Using 2019 external data')\n","    if INC2018[fold]:\n","        files_train += tf.io.gfile.glob([GCS_PATH2[fold] + '/train%.2i*.tfrec'%x for x in idxT*2])\n","        print('#### Using 2018+2017 external data')\n","    np.random.shuffle(files_train); print('#'*25)\n","    files_valid = tf.io.gfile.glob([GCS_PATH[fold] + '/train%.2i*.tfrec'%x for x in idxV])\n","    files_test = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[fold] + '/test*.tfrec')))\n","    \n","    # BUILD MODEL\n","    K.clear_session()\n","    with strategy.scope():\n","        model = build_model(dim=IMG_SIZES[fold],ef=EFF_NETS[fold])\n","        # model = get_model()\n","        \n","    # SAVE BEST MODEL EACH FOLD\n","    checkpoint_file_best_AUC = f'{MODEL}/fold-%i-bestAUC.h5'%fold\n","    sv = tf.keras.callbacks.ModelCheckpoint(\n","        checkpoint_file_best_AUC, monitor='val_auc', verbose=1, save_best_only=True,\n","        save_weights_only=True, mode='max', save_freq='epoch')\n","    \n","    checkpoint_file_best_loss = f'{MODEL}/fold-%i-bestloss.h5'%fold\n","    sv2 = tf.keras.callbacks.ModelCheckpoint(\n","        checkpoint_file_best_loss, monitor='val_loss', verbose=1, save_best_only=True,\n","        save_weights_only=True, mode='min', save_freq='epoch')\n","   \n","    # TRAIN\n","    print('Training...')\n","    # history = model.fit(\n","    #     get_dataset(files_train, augment=True, shuffle=True, repeat=True,\n","    #             dim=IMG_SIZES[fold], batch_size = BATCH_SIZES[fold],\n","    #             droprate=DROP_FREQ[fold], dropct=DROP_CT[fold], dropsize=DROP_SIZE[fold]), \n","    #     epochs=EPOCHS[fold], callbacks = [sv,sv2,get_lr_callback(BATCH_SIZES[fold])], \n","    #     steps_per_epoch=count_data_items(files_train)/BATCH_SIZES[fold]//REPLICAS,\n","    #     validation_data=get_dataset(files_valid,augment=False,shuffle=False,\n","    #             repeat=False,dim=IMG_SIZES[fold], batch_size=BATCH_SIZES[fold]), #class_weight = {0:1,1:2},\n","    #     verbose=VERBOSE\n","    # )\n","    \n","    #save a copy iof the model to gdrive\n","    # dest = f'\"/content/gdrive/My Drive/saved_models/{MODEL}/\"'\n","    # os.system(f\"cp -rf {checkpoint_file_best_loss} {dest}\")\n","    # os.system(f\"cp -rf {checkpoint_file_best_AUC} {dest}\")\n","    print('Loading best model val loss...')\n","    model.load_weights(checkpoint_file_best_loss)\n","\n","    # PREDICT OOF USING TTA\n","    print('Predicting OOF with TTA...')\n","    ds_valid = get_dataset(files_valid,labeled=False,return_image_names=False,augment=True,\n","            repeat=True,shuffle=False,dim=IMG_SIZES[fold],batch_size=BATCH_SIZES[fold],\n","            droprate=DROP_FREQ[fold], dropct=DROP_CT[fold], dropsize=DROP_SIZE[fold])\n","    ct_valid = count_data_items(files_valid); STEPS = TTA * ct_valid/BATCH_SIZES[fold]/REPLICAS\n","    pred = model.predict(ds_valid,steps=STEPS,verbose=VERBOSE)[:TTA*ct_valid,] \n","    oof_pred.append( np.mean(pred.reshape((ct_valid,TTA),order='F'),axis=1) )                 \n","    #oof_pred.append(model.predict(get_dataset(files_valid,dim=IMG_SIZES[fold]),verbose=1))\n","\n","    # GET OOF TARGETS AND NAMES\n","    ds_valid = get_dataset(files_valid, augment=False, repeat=False, dim=IMG_SIZES[fold],\n","            labeled=True, return_image_names=True)\n","    oof_tar.append( np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]) )\n","    oof_folds.append( np.ones_like(oof_tar[-1],dtype='int8')*fold )\n","    ds = get_dataset(files_valid, augment=False, repeat=False, dim=IMG_SIZES[fold],\n","                labeled=False, return_image_names=True)\n","    oof_names.append( np.array([img_name.numpy().decode(\"utf-8\") for img, img_name in iter(ds.unbatch())]))\n","\n","    # PREDICT TEST USING TTA\n","    print('Predicting Test with TTA...')\n","    ds_test = get_dataset(files_test,labeled=False,return_image_names=False,augment=True,\n","            repeat=True,shuffle=False,dim=IMG_SIZES[fold],batch_size=BATCH_SIZES[fold],\n","            droprate=DROP_FREQ[fold], dropct=DROP_CT[fold], dropsize=DROP_SIZE[fold])\n","    ct_test = count_data_items(files_test); STEPS = TTA * ct_test/BATCH_SIZES[fold]/REPLICAS\n","    pred = model.predict(ds_test,steps=STEPS,verbose=VERBOSE)[:TTA*ct_test,] \n","    tta_mean = np.mean(pred.reshape((ct_test,TTA),order='F'),axis=1)\n","    preds[:,0] += tta_mean * WGTS[fold]\n","    #new\n","\n","    preds_by_fold[:,fold] = tta_mean\n","\n","\n","    # REPORT RESULTS\n","    auc = roc_auc_score(oof_tar[-1],oof_pred[-1])\n","    #oof_val.append(np.max( history.history['val_auc'] ))\n","    print('#### FOLD %i OOF AUC without TTA = %.3f, with TTA = %.3f'%(fold+1,0,auc))\n","    \n","    # PLOT TRAINING\n","    # if DISPLAY_PLOT:\n","    #     plt.figure(figsize=(15,5))\n","    #     plt.plot(np.arange(EPOCHS[fold]),history.history['auc'],'-o',label='Train AUC',color='#ff7f0e')\n","    #     plt.plot(np.arange(EPOCHS[fold]),history.history['val_auc'],'-o',label='Val AUC',color='#1f77b4')\n","    #     x = np.argmax( history.history['val_auc'] ); y = np.max( history.history['val_auc'] )\n","    #     xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n","    #     plt.scatter(x,y,s=200,color='#1f77b4'); plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.2f'%y,size=14)\n","    #     plt.ylabel('AUC',size=14); plt.xlabel('Epoch',size=14)\n","    #     plt.legend(loc=2)\n","    #     plt2 = plt.gca().twinx()\n","    #     plt2.plot(np.arange(EPOCHS[fold]),history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n","    #     plt2.plot(np.arange(EPOCHS[fold]),history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n","    #     x = np.argmin( history.history['val_loss'] ); y = np.min( history.history['val_loss'] )\n","    #     ydist = plt.ylim()[1] - plt.ylim()[0]\n","    #     plt.scatter(x,y,s=200,color='#d62728'); plt.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n","    #     plt.ylabel('Loss',size=14)\n","    #     plt.title('FOLD %i - Image Size %i, EfficientNet B%i, inc2019=%i, inc2018=%i'%\n","    #             (fold+1,IMG_SIZES[fold],EFF_NETS[fold],INC2019[fold],INC2018[fold]),size=18)\n","    #     plt.legend(loc=3)\n","    #     plt.show()\n","    #     #break\n","      \n","    del model\n","    z = gc.collect()"],"execution_count":27,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.51.118.138:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.51.118.138:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.51.118.138:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.51.118.138:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"stream","text":["#########################\n","#### FOLD 1\n","#### Image Size 768 with {MODEL_NAME} EfficientNet B6 and batch_size 64\n","#### Using 2018+2017 external data\n","#########################\n","Training...\n","Loading best model val loss...\n","Predicting OOF with TTA...\n","2554/2553 [==============================] - 740s 290ms/step\n","Predicting Test with TTA...\n","4290/4289 [==============================] - 1249s 291ms/step\n","#### FOLD 1 OOF AUC without TTA = 0.000, with TTA = 0.923\n","WARNING:tensorflow:TPU system grpc://10.51.118.138:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.51.118.138:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.51.118.138:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.51.118.138:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"stream","text":["#########################\n","#### FOLD 2\n","#### Image Size 768 with {MODEL_NAME} EfficientNet B6 and batch_size 64\n","#### Using 2018+2017 external data\n","#########################\n","Training...\n","Loading best model val loss...\n","Predicting OOF with TTA...\n","2553/2552 [==============================] - 748s 293ms/step\n","Predicting Test with TTA...\n","4290/4289 [==============================] - 1262s 294ms/step\n","#### FOLD 2 OOF AUC without TTA = 0.000, with TTA = 0.900\n","WARNING:tensorflow:TPU system grpc://10.51.118.138:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.51.118.138:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.51.118.138:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.51.118.138:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"stream","text":["#########################\n","#### FOLD 3\n","#### Image Size 768 with {MODEL_NAME} EfficientNet B6 and batch_size 64\n","#### Using 2018+2017 external data\n","#########################\n","Training...\n","Loading best model val loss...\n","Predicting OOF with TTA...\n","2560/2559 [==============================] - 749s 293ms/step\n","Predicting Test with TTA...\n","4290/4289 [==============================] - 1261s 294ms/step\n","#### FOLD 3 OOF AUC without TTA = 0.000, with TTA = 0.955\n","WARNING:tensorflow:TPU system grpc://10.51.118.138:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.51.118.138:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.51.118.138:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.51.118.138:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"stream","text":["#########################\n","#### FOLD 4\n","#### Image Size 768 with {MODEL_NAME} EfficientNet B6 and batch_size 64\n","#### Using 2018+2017 external data\n","#########################\n","Training...\n","Loading best model val loss...\n","Predicting OOF with TTA...\n","2545/2544 [==============================] - 746s 293ms/step\n","Predicting Test with TTA...\n","4290/4289 [==============================] - 1263s 294ms/step\n","#### FOLD 4 OOF AUC without TTA = 0.000, with TTA = 0.935\n","WARNING:tensorflow:TPU system grpc://10.51.118.138:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.51.118.138:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.51.118.138:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.51.118.138:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stderr"},{"output_type":"stream","text":["#########################\n","#### FOLD 5\n","#### Image Size 768 with {MODEL_NAME} EfficientNet B6 and batch_size 64\n","#### Using 2018+2017 external data\n","#########################\n","Training...\n","Loading best model val loss...\n","Predicting OOF with TTA...\n","2561/2560 [==============================] - 753s 294ms/step\n","Predicting Test with TTA...\n","4290/4289 [==============================] - 1265s 295ms/step\n","#### FOLD 5 OOF AUC without TTA = 0.000, with TTA = 0.919\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gty_zRzYmYSG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":134},"executionInfo":{"status":"ok","timestamp":1596969733451,"user_tz":-120,"elapsed":1134,"user":{"displayName":"Marc Mauri","photoUrl":"","userId":"05962595886095771500"}},"outputId":"95145df9-7d93-4b77-b2dc-2f9a995ab199"},"source":["preds_by_fold"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.02320415, 0.05501137, 0.02483676, 0.01697469, 0.04787888],\n","       [0.00679143, 0.01285417, 0.01399828, 0.00962543, 0.02389843],\n","       [0.01264326, 0.01427788, 0.04549006, 0.00804127, 0.03165356],\n","       ...,\n","       [0.07890698, 0.07530045, 0.04968209, 0.0379742 , 0.04989181],\n","       [0.10396729, 0.11150019, 0.07201093, 0.08554515, 0.0652191 ],\n","       [0.01882151, 0.02527134, 0.02905571, 0.04142674, 0.03407995]])"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"98X3yWimbrXD","colab_type":"text"},"source":["## Calculate OOF AUC\n","The OOF (out of fold) predictions are saved to disk. If you wish to ensemble multiple models, use the OOF to determine what are the best weights to blend your models with. Choose weights that maximize OOF CV score when used to blend OOF. Then use those same weights to blend your test predictions."]},{"cell_type":"code","metadata":{"id":"lEV-LiajbrXE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":212},"executionInfo":{"status":"ok","timestamp":1596969739466,"user_tz":-120,"elapsed":1610,"user":{"displayName":"Marc Mauri","photoUrl":"","userId":"05962595886095771500"}},"outputId":"e03f0733-6ee6-416a-861f-3f22c1347b9d"},"source":["# COMPUTE OVERALL OOF AUC\n","oof = np.concatenate(oof_pred); \n","true = np.concatenate(oof_tar);\n","names = np.concatenate(oof_names); folds = np.concatenate(oof_folds)\n","auc = roc_auc_score(true,oof)\n","print('Overall OOF AUC with TTA = %.3f'%auc)\n","\n","# SAVE OOF TO DISK\n","df_oof = pd.DataFrame(dict(\n","    image_name = names, target=true, pred = oof, fold=folds))\n","df_oof.to_csv(f'{MODEL}/oof.csv',index=False)\n","df_oof.head()"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Overall OOF AUC with TTA = 0.926\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image_name</th>\n","      <th>target</th>\n","      <th>pred</th>\n","      <th>fold</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ISIC_2637011</td>\n","      <td>0.0</td>\n","      <td>0.099978</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ISIC_0076262</td>\n","      <td>0.0</td>\n","      <td>0.032412</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ISIC_0074268</td>\n","      <td>0.0</td>\n","      <td>0.004452</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ISIC_0015719</td>\n","      <td>0.0</td>\n","      <td>0.014257</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ISIC_0082543</td>\n","      <td>0.0</td>\n","      <td>0.006928</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     image_name  target      pred  fold\n","0  ISIC_2637011     0.0  0.099978     0\n","1  ISIC_0076262     0.0  0.032412     0\n","2  ISIC_0074268     0.0  0.004452     0\n","3  ISIC_0015719     0.0  0.014257     0\n","4  ISIC_0082543     0.0  0.006928     0"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"O_u9fQZB7Q-j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596969744341,"user_tz":-120,"elapsed":1273,"user":{"displayName":"Marc Mauri","photoUrl":"","userId":"05962595886095771500"}},"outputId":"fb41d8a5-f45b-4d3d-baaa-f1abf92b98d3"},"source":["auc_oof = 0.0\n","for i in range(FOLDS):\n","  auc_oof += roc_auc_score(oof_tar[i], oof_pred[i]) / FOLDS\n","print('Average OOF AUC with TTA = %.3f'%auc_oof)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Average OOF AUC with TTA = 0.927\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"a3nkiD-ObrXH","colab_type":"text"},"source":["# Step 5: Post process\n","There are ways to modify predictions based on patient information to increase CV LB. You can experiment with that here on your OOF.\n","\n","Aqui, hauriem de posar les features amb XGB, CB, o el que sigui\n","OptimizeAUC() del llibre de l'Abishek per trobar els pesos de diferents models per a cada fold\n","\n","I fer servir el OptimizeAUC per veure els pesos de la metadata"]},{"cell_type":"markdown","metadata":{"id":"gKXGQl-KbrXH","colab_type":"text"},"source":["# Submit To Kaggle"]},{"cell_type":"code","metadata":{"id":"CxRaE7TkbrXI","colab_type":"code","colab":{}},"source":["ds = get_dataset(files_test, augment=False, repeat=False, dim=IMG_SIZES[fold],\n","                 labeled=False, return_image_names=True)\n","\n","image_names = np.array([img_name.numpy().decode(\"utf-8\") \n","                        for img, img_name in iter(ds.unbatch())])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SCx-_b9GbrXK","colab_type":"code","colab":{}},"source":["submission = pd.DataFrame(dict(image_name=image_names, target=preds[:,0]))\n","submission = submission.sort_values('image_name') \n","submission.to_csv(f'{MODEL}/submission.csv', index=False)\n","submission.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y3yAOlWRbrXN","colab_type":"code","colab":{}},"source":["plt.hist(submission.target,bins=100)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6KqtL28QjRGR","colab_type":"code","colab":{}},"source":["out_preds_by_fold = np.append(np.vstack(image_names), preds_by_fold, 1)\n","submission_by_fold = pd.DataFrame(out_preds_by_fold)\n","\n","# #submission = submission.sort_values('image_name') \n","submission_by_fold.to_csv(f'{MODEL}/preds_by_fold.csv', index=False)\n","submission_by_fold.head()\n","# submission.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tbQewR479Gvw","colab_type":"code","colab":{}},"source":["preds_by_fold.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pkCrbhAqMl1d","colab_type":"code","colab":{}},"source":["from scipy.stats import rankdata\n","\n","ranked_submission = pd.DataFrame(dict(image_name=image_names, target=0))\n","\n","ranked_submission['target'] = 0\n","for i in range(FOLDS):\n","    ranked_submission['target'] += rankdata(preds_by_fold[:,i]) / (FOLDS)\n","\n","ranked_submission = ranked_submission.sort_values('image_name') "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qKsDn9ThAMTo","colab_type":"code","colab":{}},"source":["ranked_submission.head(100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WF1bq3StF93l","colab_type":"code","colab":{}},"source":["ranked_submission['target'].mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B0osKKaKORvu","colab_type":"code","colab":{}},"source":["ranked_submission.to_csv(f'{MODEL}/submission_ranked.csv', index=False)\n","\n","plt.hist(ranked_submission.target,bins=100)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dqTqcnk9QFAn","colab_type":"code","colab":{}},"source":["import os\n","src = f'/content/{MODEL}'\n","dest = f'\"/content/gdrive/My Drive/saved_models/{MODEL}\"'\n","os.system(f\"rm -rf {dest}\")\n","os.system(f\"cp -rf {src} {dest}\")\n","print (src)\n","print(dest)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kc0rd3UKHu1J","colab_type":"code","colab":{}},"source":["import re\n","import json\n","import requests\n","import ipykernel\n","from notebook.notebookapp import list_running_servers\n","from requests.compat import urljoin\n","\n","def get_notebook_name():\n","    \"\"\"\n","    Return the full path of the jupyter notebook.\n","    \"\"\"\n","    kernel_id = re.search('kernel-(.*).json', ipykernel.connect.get_connection_file()).group(1)\n","    servers = list_running_servers()\n","    for ss in servers:\n","        response = requests.get(urljoin(ss['url'], 'api/sessions'), params={'token': ss.get('token', '')})\n","        for nn in response.json():\n","            if nn['kernel']['id'] == kernel_id:\n","                notebook_name = nn['notebook']['name']\n","                return notebook_name\n","\n","NOTEBOOK_NAME = get_notebook_name()\n","copyNotebook = f'cp \"/content/gdrive/My Drive/Colab Notebooks/{NOTEBOOK_NAME}\" \"/content/gdrive/My Drive/saved_models/{MODEL}/train.ipynb\"'\n","os.system(copyNotebook)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lbR88xM-KsA7","colab_type":"code","colab":{}},"source":["!kaggle competitions submit -c siim-isic-melanoma-classification -f {MODEL}/submission.csv -m \"{MODEL}\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dLjBO5YzCxJw","colab_type":"code","colab":{}},"source":["#!kaggle competitions submit -c siim-isic-melanoma-classification -f {MODEL}/submission_ranked.csv -m \"{MODEL}-Ranked\""],"execution_count":null,"outputs":[]}]}